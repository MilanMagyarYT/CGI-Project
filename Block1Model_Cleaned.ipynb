{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e12d785c-f6e8-4505-94aa-87d0862f64a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_271758/4118134586.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  sensor_data[column].fillna(avg_std, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-auc:0.90512\n",
      "[1]\ttest-auc:0.90958\n",
      "[2]\ttest-auc:0.91607\n",
      "[3]\ttest-auc:0.92073\n",
      "[4]\ttest-auc:0.92363\n",
      "[5]\ttest-auc:0.92402\n",
      "[6]\ttest-auc:0.92461\n",
      "[7]\ttest-auc:0.92539\n",
      "[8]\ttest-auc:0.92606\n",
      "[9]\ttest-auc:0.92578\n",
      "[10]\ttest-auc:0.92623\n",
      "[11]\ttest-auc:0.92571\n",
      "[12]\ttest-auc:0.92558\n",
      "[13]\ttest-auc:0.92573\n",
      "[14]\ttest-auc:0.92534\n",
      "[15]\ttest-auc:0.92475\n",
      "[16]\ttest-auc:0.92543\n",
      "[17]\ttest-auc:0.92512\n",
      "[18]\ttest-auc:0.92496\n",
      "[19]\ttest-auc:0.92507\n",
      "[20]\ttest-auc:0.92473\n",
      "First few prediction percentages: ['2.72%', '15.04%', '77.43%', '7.42%', '7.57%']\n",
      "Accuracy: 0.8736052481460354\n",
      "Precision: 0.20445103857566765\n",
      "Recall: 0.886031184696994\n",
      "F1 Score: 0.33223832916428075\n",
      "Confusion Matrix:\n",
      "[[147631  21448]\n",
      " [   709   5512]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the paths to your datasets\n",
    "sensor_data_path = r'telemetry.csv'\n",
    "failure_data_path = r'failures.csv'\n",
    "\n",
    "# Load the sensor data\n",
    "sensor_data = pd.read_csv(sensor_data_path)\n",
    "\n",
    "# Load the failure data\n",
    "failure_data = pd.read_csv(failure_data_path)\n",
    "\n",
    "# Convert datetime columns to datetime type for both datasets\n",
    "sensor_data['datetime'] = pd.to_datetime(sensor_data['datetime'])\n",
    "failure_data['datetime'] = pd.to_datetime(failure_data['datetime'])\n",
    "\n",
    "sensor_data.set_index('datetime', inplace=True)\n",
    "\n",
    "# Sort by datetime to ensure rolling windows work correctly\n",
    "sensor_data.sort_index(inplace=True)\n",
    "\n",
    "# Choose a window size, e.g., 24 hours\n",
    "window_size = '24h'\n",
    "\n",
    "# Create rolling features for each sensor\n",
    "for column in ['volt', 'rotate', 'pressure', 'vibration']:\n",
    "    sensor_data[f'{column}_mean'] = sensor_data.groupby('machineID')[column].transform(lambda x: x.rolling(window_size).mean())\n",
    "    sensor_data[f'{column}_std'] = sensor_data.groupby('machineID')[column].transform(lambda x: x.rolling(window_size).std())\n",
    "\n",
    "# For each standard deviation column, fill NaN values with the average of available standard deviations for that sensor\n",
    "for column in ['volt_std', 'rotate_std', 'pressure_std', 'vibration_std']:\n",
    "    # Calculate the average standard deviation for the column, excluding NaN values\n",
    "    avg_std = sensor_data[column].mean()\n",
    "    \n",
    "    # Fill NaN values in the standard deviation column with this average standard deviation\n",
    "    sensor_data[column].fillna(avg_std, inplace=True)\n",
    "\n",
    "# Initialize a column for labels\n",
    "sensor_data['failure_within_48h'] = 0\n",
    "\n",
    "# For each failure, mark the preceding 48 hours as positive examples\n",
    "for index, row in failure_data.iterrows():\n",
    "    start_time = row['datetime'] - pd.Timedelta(hours=48)\n",
    "    end_time = row['datetime']\n",
    "    machine_id = row['machineID']\n",
    "    \n",
    "    sensor_data.loc[(sensor_data.index > start_time) & (sensor_data.index <= end_time) & (sensor_data['machineID'] == machine_id), 'failure_within_48h'] = 1\n",
    "\n",
    "# Split the data based on a date. For example, use the last 20% of the dates as the test set.\n",
    "split_date = sensor_data.index.max() - pd.Timedelta(days=365 * 0.2)  # Adjust based on your dataset's date range\n",
    "\n",
    "train_data = sensor_data[sensor_data.index < split_date]\n",
    "test_data = sensor_data[sensor_data.index >= split_date]\n",
    "\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Features and target variable\n",
    "X_train = train_data.drop(['failure_within_48h', 'machineID'], axis=1)\n",
    "y_train = train_data['failure_within_48h']\n",
    "X_test = test_data.drop(['failure_within_48h', 'machineID'], axis=1)\n",
    "y_test = test_data['failure_within_48h']\n",
    "\n",
    "# Apply SMOTE to balance the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Since we've applied SMOTE, convert the resampled datasets to DMatrix for XGBoost\n",
    "dtrain_resampled = xgb.DMatrix(X_train_resampled, label=y_train_resampled)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Define XGBoost parameters\n",
    "params = {\n",
    "    'max_depth': 6,  # Depth of each tree\n",
    "    'eta': 0.3,  # Learning rate\n",
    "    'objective': 'binary:logistic',  # Binary classification\n",
    "    'eval_metric': 'auc',  # Evaluation metric\n",
    "    'nthread': 4  # Number of cores to use\n",
    "}\n",
    "\n",
    "num_boost_round = 100\n",
    "\n",
    "# Train the model on the resampled (balanced) dataset\n",
    "bst_resampled = xgb.train(params, dtrain_resampled, num_boost_round, evals=[(dtest, 'test')], early_stopping_rounds=10)\n",
    "\n",
    "# Predict the probabilities of failure\n",
    "y_pred_proba_resampled = bst_resampled.predict(dtest)\n",
    "\n",
    "# Convert probabilities to percentages\n",
    "y_pred_percentages = [f\"{x * 100:.2f}%\" for x in y_pred_proba_resampled]\n",
    "\n",
    "# Print the first few predictions to check\n",
    "print(\"First few prediction percentages:\", y_pred_percentages[:5])\n",
    "\n",
    "# Convert probabilities to binary predictions using a threshold, e.g., 0.5\n",
    "y_pred_resampled = [1 if x > 0.5 else 0 for x in y_pred_proba_resampled]\n",
    "\n",
    "# Calculate and print accuracy, precision, recall, and F1 score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_resampled))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_resampled))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_resampled))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_resampled))\n",
    "\n",
    "# Generate and print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_resampled)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'datetime': test_data.index,\n",
    "    'machineID': test_data['machineID'],\n",
    "    'prediction': y_pred_resampled,\n",
    "    'confidence': y_pred_percentages  # Confidence scores as percentages\n",
    "})\n",
    "\n",
    "results_df.to_csv('prediction_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11d08b2-7eee-405b-8c7e-4aec4bda6fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
